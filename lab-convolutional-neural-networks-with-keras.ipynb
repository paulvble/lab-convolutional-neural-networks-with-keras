{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will learn how to use the Keras library to build convolutional neural networks. We will also use the popular MNIST dataset and we will compare our results to using a conventional neural network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Convolutional Neural Networks with Keras</h2>\n",
    "\n",
    "<h3>Objective for this Notebook<h3>    \n",
    "<h5> 1. How to use the Keras library to build convolutional neural networks.</h5>\n",
    "<h5> 2. Convolutional Neural Network with One Convolutional and Pooling Layers.</h5>\n",
    "<h5> 3. Convolutional Neural Network with Two Convolutional and Pooling Layers.</h5>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "<font size = 3>\n",
    "      \n",
    "1. <a href=\"#item41\">Import Keras and Packages</a>   \n",
    "2. <a href=\"#item42\">Convolutional Neural Network with One Convolutional and Pooling Layers</a>  \n",
    "3. <a href=\"#item43\">Convolutional Neural Network with Two Convolutional and Pooling Layers</a>  \n",
    "\n",
    "</font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item41'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Keras and Packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing the keras libraries and the packages that we would need to build a neural network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 16:37:17.999168: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with convolutional neural networks in particular, we will need additional packages.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item42'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Layer with One set of convolutional and pooling layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's normalize the pixel values to be between 0 and 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255 # normalize training data\n",
    "X_test = X_test / 255 # normalize test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's convert the target variable into binary categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "num_classes = y_test.shape[1] # number of categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's define a function that creates our model. Let's start with one set of convolutional and pooling layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_model():\n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (5, 5), strides=(1, 1), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's call the function to create the model, and then let's train it and evaluate it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 - 13s - 44ms/step - accuracy: 0.9190 - loss: 0.2884 - val_accuracy: 0.9730 - val_loss: 0.0944\n",
      "Epoch 2/10\n",
      "300/300 - 15s - 50ms/step - accuracy: 0.9758 - loss: 0.0840 - val_accuracy: 0.9795 - val_loss: 0.0654\n",
      "Epoch 3/10\n",
      "300/300 - 13s - 45ms/step - accuracy: 0.9826 - loss: 0.0574 - val_accuracy: 0.9804 - val_loss: 0.0566\n",
      "Epoch 4/10\n",
      "300/300 - 13s - 45ms/step - accuracy: 0.9855 - loss: 0.0475 - val_accuracy: 0.9834 - val_loss: 0.0477\n",
      "Epoch 5/10\n",
      "300/300 - 14s - 45ms/step - accuracy: 0.9888 - loss: 0.0375 - val_accuracy: 0.9850 - val_loss: 0.0461\n",
      "Epoch 6/10\n",
      "300/300 - 14s - 47ms/step - accuracy: 0.9909 - loss: 0.0307 - val_accuracy: 0.9864 - val_loss: 0.0420\n",
      "Epoch 7/10\n",
      "300/300 - 12s - 41ms/step - accuracy: 0.9924 - loss: 0.0256 - val_accuracy: 0.9878 - val_loss: 0.0388\n",
      "Epoch 8/10\n",
      "300/300 - 12s - 40ms/step - accuracy: 0.9931 - loss: 0.0219 - val_accuracy: 0.9860 - val_loss: 0.0450\n",
      "Epoch 9/10\n",
      "300/300 - 12s - 42ms/step - accuracy: 0.9948 - loss: 0.0172 - val_accuracy: 0.9889 - val_loss: 0.0335\n",
      "Epoch 10/10\n",
      "300/300 - 21s - 71ms/step - accuracy: 0.9953 - loss: 0.0154 - val_accuracy: 0.9879 - val_loss: 0.0372\n",
      "Accuracy: 0.9879000186920166 \n",
      " Error: 1.2099981307983398\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = convolutional_model()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item43'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Layer with two sets of convolutional and pooling layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's redefine our convolutional model so that it has two convolutional and pooling layers instead of just one layer of each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_model():\n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
    "    \n",
    "    # Add a Conv2D layer with 16 filters, kernel size 5x5, ReLU activation, and input shape 28x28x1\n",
    "    model.add(Conv2D(16, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
    "    \n",
    "    # Add a 2D max pool layer with a pool size of 2x2 and a stride of 2\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    # Add another Conv2D layer with 8 filters and a kernel size of 2x2\n",
    "    model.add(Conv2D(8, (2, 2), activation='relu'))\n",
    "    \n",
    "    # Flatten the output\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Add a dense layer with 100 neurons\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    \n",
    "    # Add a final dense layer with the number of classes (assuming 10 classes for this example) and softmax activation\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's call the function to create our new convolutional neural network, and then let's train it and evaluate it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 - 51s - 170ms/step - accuracy: 0.9179 - loss: 0.2791 - val_accuracy: 0.9774 - val_loss: 0.0757\n",
      "Epoch 2/10\n",
      "300/300 - 49s - 162ms/step - accuracy: 0.9772 - loss: 0.0757 - val_accuracy: 0.9829 - val_loss: 0.0555\n",
      "Epoch 3/10\n",
      "300/300 - 44s - 146ms/step - accuracy: 0.9837 - loss: 0.0520 - val_accuracy: 0.9880 - val_loss: 0.0398\n",
      "Epoch 4/10\n",
      "300/300 - 47s - 156ms/step - accuracy: 0.9880 - loss: 0.0386 - val_accuracy: 0.9888 - val_loss: 0.0345\n",
      "Epoch 5/10\n",
      "300/300 - 47s - 157ms/step - accuracy: 0.9901 - loss: 0.0310 - val_accuracy: 0.9898 - val_loss: 0.0329\n",
      "Epoch 6/10\n",
      "300/300 - 48s - 159ms/step - accuracy: 0.9921 - loss: 0.0248 - val_accuracy: 0.9887 - val_loss: 0.0367\n",
      "Epoch 7/10\n",
      "300/300 - 82s - 272ms/step - accuracy: 0.9926 - loss: 0.0230 - val_accuracy: 0.9898 - val_loss: 0.0319\n",
      "Epoch 8/10\n",
      "300/300 - 49s - 164ms/step - accuracy: 0.9943 - loss: 0.0175 - val_accuracy: 0.9899 - val_loss: 0.0306\n",
      "Epoch 9/10\n",
      "300/300 - 50s - 168ms/step - accuracy: 0.9951 - loss: 0.0154 - val_accuracy: 0.9916 - val_loss: 0.0281\n",
      "Epoch 10/10\n",
      "300/300 - 56s - 187ms/step - accuracy: 0.9954 - loss: 0.0134 - val_accuracy: 0.9911 - val_loss: 0.0310\n",
      "Accuracy: 0.991100013256073 \n",
      " Error: 0.8899986743927002\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = convolutional_model()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thank you for completing this lab!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
